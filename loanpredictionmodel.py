# -*- coding: utf-8 -*-
"""LoanPredictionModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Htqzmr3UAPBjQaGBWyfIcsy9t5y_AdM4

# Creating DataFrame
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

dataframe=pd.read_csv('/content/drive/MyDrive/train_u6lujuX_CVtuZ9i (1).csv')
dataframe.head(1)

dataframe.shape

"""# Data Preprocessing"""

dataframe.duplicated().sum()

dataframe.drop_duplicates(keep='first',inplace=True)
dataframe.shape

dataframe.T.drop_duplicates(keep='first',inplace=True)
dataframe.shape

dataframe.dropna(how='all',axis=0,inplace=True)
dataframe.shape

dataframe.isnull().sum()

dataframe.dropna(how='any',axis=0,subset=['LoanAmount','Loan_Amount_Term'],inplace=True)
dataframe.head()

dataframe.shape

dataframe.describe()

dataframe['Gender'].fillna(value=dataframe['Gender'].mode()[0],inplace=True)
dataframe['Married'].fillna(dataframe['Married'].mode()[0],inplace= True)
dataframe['Dependents'].fillna(dataframe['Dependents'].mode()[0],inplace= True)
dataframe['Self_Employed'].fillna(dataframe['Self_Employed'].mode()[0],inplace= True)
dataframe['Credit_History'].fillna(dataframe['Credit_History'].mode()[0],inplace=True)
dataframe.isnull().sum()

dataframe.head()

"""# Feature Engineering"""

dataframe.dtypes

print(dataframe.Gender.value_counts())
print(dataframe.Married.value_counts())
print(dataframe.Dependents.value_counts())
print(dataframe.Education.value_counts())
print(dataframe.Self_Employed.value_counts())
print(dataframe.Property_Area.value_counts())
print(dataframe.Loan_Status.value_counts())

dataframe['Loan_Status'].replace('N',0,inplace=True)
dataframe['Loan_Status'].replace('Y',1,inplace=True)

dataframe['Married'].replace('No',2,inplace=True)
dataframe['Married'].replace('Yes',1,inplace=True)
dataframe.replace({'Gender':{'Male':1,'Female':2}},inplace=True)
dataframe.replace({'Education':{'Graduate':1,'Not Graduate':2}},inplace=True)
dataframe.replace({'Self_Employed':{'Yes':1,'No':0}},inplace=True)
dataframe['Dependents'].replace('3+',3,inplace=True)
#dataframe.replace({'Property_Area':{'Rural':0,'Semiurban':1,'Urban':2}},inplace=True)
dataframe.head()

dataframe.drop(['Loan_ID'],axis=1,inplace=True)
print(dataframe.shape)
print(dataframe.head())

dataframe = pd.get_dummies(dataframe)
dataframe.head

"""# Exploratory Data Analysis

"""

dataframe.describe()

import seaborn as sns
from sklearn.model_selection import train_test_split

dataframe.hist(figsize=(20,20))

sns.boxplot(x=dataframe['ApplicantIncome'])

threshold=dataframe['ApplicantIncome'].quantile(.97)
print(threshold)
dataframe=dataframe[dataframe['ApplicantIncome']<threshold]
print(dataframe.shape)
dataframe.head()

sns.boxplot(x=dataframe['Loan_Amount_Term'])

dataframe['Loan_Amount_Term'].value_counts()

dataframe=dataframe[dataframe['Loan_Amount_Term']>=180]
dataframe.shape

sns.boxplot(x=dataframe['CoapplicantIncome'])

dataframe.describe()

dataframe['TotalIncome']=dataframe['ApplicantIncome']+dataframe['CoapplicantIncome']

dataframe['CoapplicantIncome'].replace(0,dataframe['CoapplicantIncome'].mean(),inplace=True)
threshold=dataframe['CoapplicantIncome'].quantile(.96)
print(threshold)
dataframe=dataframe[dataframe['CoapplicantIncome']<threshold]
print(dataframe.shape)
#dataframe['CoapplicantIncome'].replace(0,dataframe['CoapplicantIncome'].mean(),inplace=True)
#sns.distplot(ndd['CoapplicantIncome'])
dataframe['CoapplicantIncome'].hist(figsize=(15,15))

sns.boxplot(x=dataframe['LoanAmount'])

threshold=dataframe['LoanAmount'].quantile(.97)
print(threshold)
dataframe=dataframe[dataframe['LoanAmount']<threshold]
sns.distplot(dataframe['LoanAmount'])
dataframe.shape
# print(dataframe.shape)
# dataframe.head()

nf=dataframe.dtypes[dataframe.dtypes!='object'].index
sf=dataframe[nf].skew().sort_values(ascending=False)
skewness=pd.DataFrame({'Skew':sf})
skewness

dataframe=dataframe.reset_index()
dataframe.tail()

dataframe.drop(['index'],axis=1,inplace=True)
dataframe.tail()

dataframe['ApplicantIncome']=np.log(dataframe['ApplicantIncome'])
# #nd=(dataframe['ApplicantIncome'])**2
sns.distplot(dataframe['ApplicantIncome'])

dataframe['TotalIncome']=np.log(dataframe['TotalIncome'])
sns.distplot(dataframe['TotalIncome'])

dataframe['CoapplicantIncome']=np.log(dataframe['CoapplicantIncome'])
# #nd=(dataframe['CoapplicantIncome'])**2
sns.distplot(dataframe['CoapplicantIncome'])

dataframe['LoanAmount']=np.log(dataframe['LoanAmount'])
sns.distplot(dataframe['LoanAmount'])

dataframe.hist(figsize=(25,25))

dataframe.describe()

dataframe['Loan_Amount_Term'].value_counts()

dataframe.replace({'Loan_Amount_Term':{360.0:5,180.0:4,480.0:3,300.0:2,240.0:1}},inplace=True)

dataframe.dtypes

# dataframe['Dependents']=dataframe['Dependents'].astype(int)
dataframe['Loan_Amount_Term']=dataframe['Loan_Amount_Term'].astype(int)
dataframe['Credit_History']=dataframe['Credit_History'].astype(int)

"""# Feature Selection"""

sns.set(rc = {'figure.figsize':(25,15)})
sns.heatmap(dataframe.corr(),linewidths = 0.30,annot=True)

"""credit history, 
property area semiurban,
loan amount 
married with gender and dependents,
applicant income with loan amount and self employed and education,
coapplicant income with loan amount,


"""

# Commented out IPython magic to ensure Python compatibility.
X=dataframe.drop(['Loan_Status'],axis=1)
Y=dataframe['Loan_Status']
from sklearn.feature_selection import mutual_info_classif
import matplotlib.pyplot as plt
# %matplotlib inline
imp=mutual_info_classif(X,Y)
fi=pd.Series(imp,dataframe.columns[0:len(dataframe.columns)-1])
fi=fi.sort_values()
fi.plot(kind='barh', color='teal')
plt.show()
print(fi)

"""credit history, loan amount term 240, married, applicant income, self employed, education"""

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
Xc=X.astype(int)
chi2f=SelectKBest(chi2,k=3)
xkbestf=chi2f.fit_transform(Xc,Y)
# print('total',Xc.shape[1])
# print('reduced',xkbestf.shape[1])
# xkfi=pd.Series(xkbestf[1],dataframe.columns[0:len(dataframe.columns)-1])
# xkfi=xkfi.sort_values()
# 
xkbestf[:5]

"""applicant income, credit history,"""

from sklearn.ensemble import RandomForestClassifier
model=RandomForestClassifier(n_estimators=340)
model.fit(X,Y)
imp=model.feature_importances_
fd=pd.DataFrame({'Features':pd.DataFrame(X).columns,'Importances':imp})
fd.set_index('Importances')
fd=fd.sort_values('Importances')
fd.plot.bar(color='teal')
print(fd)

"""credit history, applicant income, loan amount, coapplicant income, married, education"""

# train_features = ['Credit_History', 'Education', 'Gender','Property_Area_Semiurban','LoanAmount','ApplicantIncome','CoapplicantIncome','Married']

train_features = ['Credit_History','TotalIncome','ApplicantIncome','Loan_Amount_Term','CoapplicantIncome','Married','Property_Area_Semiurban','Dependents_2','LoanAmount']

X = dataframe[train_features]
#X = dataframe.drop(['Loan_Status'],axis=1)
y = dataframe['Loan_Status']
print(X.shape)
print(y.shape)

"""# Modeling

**Splitting Data to Train Test**
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)
print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

"""**Scalling**"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.linear_model import LogisticRegression

from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score,f1_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix

from sklearn.metrics import precision_recall_curve
from sklearn import metrics
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

"""**I. Logistic Regression**"""

lrmodel=LogisticRegression()
lrmodel.fit(X_train, y_train)
predicted = lrmodel.predict(X_test)
print('LOGISTIC REGRESSION')
print(classification_report(y_test,predicted))

accuracy1 = lrmodel.score(X_test, y_test)
recall1 = recall_score(y_test,predicted)
precision1 = precision_score(y_test,predicted)
f1score1 =f1_score(y_test,predicted)
#print('accuracy_score overall :', score)
print('accuracy_score percent :', round(accuracy1*100,2))
print('Precision percent :',round(precision1*100,2))
print('F1 score percent :', round(f1score1*100,2))
print('Recall percent :',round(recall1*100,2))
print(confusion_matrix(y_test,predicted))

y_score = lrmodel.predict_proba(X_test)[:, 1]
precision, recall, thresholds = precision_recall_curve(y_test, y_score)

fig, ax = plt.subplots()
#plt.figure(figsize=(10, 10))
ax.plot(recall, precision, color='purple')
ax.set_title('Precision-Recall Curve')
ax.set_ylabel('Precision')
ax.set_xlabel('Recall')
ax=plt.gca()
ax.locator_params('y', nbins=10)
plt.locator_params('x', nbins=20)
plt.show()

y_roc = lrmodel.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_roc)
auc1 = metrics.roc_auc_score(y_test, y_roc)
#create ROC curve
#plt.plot(fpr,tpr)
plt.figure(figsize=(10, 10))
plt.plot(fpr,tpr,label="LRModel_AUC="+str(round(auc1,2)))
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
ax=plt.gca()
ax.locator_params('y', nbins=20)
plt.locator_params('x', nbins=20)
plt.legend(loc=4)
plt.show()

rfmodel = RandomForestClassifier(n_estimators=100,min_samples_leaf = 4,max_depth=3)
rfmodel.fit(X_train,y_train)
predictedrf = rfmodel.predict(X_test)
accuracy2 = accuracy_score(y_test,predictedrf)
f1score2 = f1_score(y_test,predictedrf)
recall2 = recall_score(y_test,predictedrf)
precision2 = precision_score(y_test,predictedrf)
print('RANDOM FOREST CLASSIFIER')
print(classification_report(y_test,predictedrf))
print("F1 Score percent", round(f1score2*100,2))
print("Accuracy percent", round(accuracy2*100,2))
print('Precision percent :',round(precision2*100,2))
print('Recall percent :',round(recall2*100,2))
print(confusion_matrix(y_test,predictedrf))
#print(accuracy_score(y_test, predicted))

y_scorerf = rfmodel.predict_proba(X_test)[:, 1]
precision, recall, thresholds = precision_recall_curve(y_test, y_scorerf)

fig1, ax1 = plt.subplots()
ax1.plot(recall, precision, color='purple')
ax1.set_title('Precision-Recall Curve')
ax1.set_ylabel('Precision')
ax1.set_xlabel('Recall')
plt.show()

y_rocrf = rfmodel.predict_proba(X_test)[::,1]
fpr1, tpr1, _ = metrics.roc_curve(y_test,  y_rocrf)
auc2 = metrics.roc_auc_score(y_test, y_rocrf)
#create ROC curve
#plt.plot(fpr1,tpr1)
plt.figure(figsize=(10, 10))
plt.plot(fpr1,tpr1,label="RFModel_AUC="+str(round(auc2,2)))
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
ax=plt.gca()
ax.locator_params('y', nbins=20)
plt.locator_params('x', nbins=20)
plt.legend(loc=4)
plt.show()

"""**III. KN Neighbor**"""

KNN_model = KNeighborsClassifier(n_neighbors = 40)
KNN_model.fit(X_train, y_train)
predknn=KNN_model.predict(X_test)
accuracy3 =accuracy_score(y_test,predknn)
f1score3 = f1_score(y_test,predknn)
recall3 = recall_score(y_test,predknn)
precision3 = precision_score(y_test,predknn)
print(classification_report(y_test,predknn))
print("KNN accuracy percent :", round(accuracy3*100,2))
print("KNN F1 Score percent :", round(f1score3*100,2))
print('Precision percent :',round(precision3*100,2))
print('Recall percent :',round(recall3*100,2))
print(confusion_matrix(y_test,predknn))

y_scoreknn = KNN_model.predict_proba(X_test)[:, 1]
precision, recall, thresholds = precision_recall_curve(y_test, y_scoreknn)

fig1, ax1 = plt.subplots()
ax1.plot(recall, precision, color='purple')
ax1.set_title('Precision-Recall Curve')
ax1.set_ylabel('Precision')
ax1.set_xlabel('Recall')
plt.show()

y_rocknn = KNN_model.predict_proba(X_test)[::,1]
fpr2, tpr2, _ = metrics.roc_curve(y_test,  y_rocknn)
auc3 = metrics.roc_auc_score(y_test, y_rocknn)
#create ROC curve
#plt.plot(fpr1,tpr1)
plt.figure(figsize=(10, 10))
plt.plot(fpr2,tpr2,label="KNNModel_AUC="+str(round(auc3,2)))
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
ax=plt.gca()
ax.locator_params('y', nbins=20)
plt.locator_params('x', nbins=20)
plt.legend(loc=4)
plt.show()

"""**IV. Decision Tree Classifier**"""

dtmodel = DecisionTreeClassifier(max_depth=3,min_samples_leaf = 4)
dtmodel.fit(X_train,y_train)
y_pred = dtmodel.predict(X_test)
accuracy4=accuracy_score(y_test,y_pred)
f1score4 = f1_score(y_test,y_pred)
recall4 = recall_score(y_test,y_pred)
precision4 = precision_score(y_test,y_pred)
print('DECISION TREE CLASSIFIER')
print(classification_report(y_test,y_pred))
print("Accuracy percent : ",round(accuracy4*100,2))
print("F1 Score percent : ",round(f1score4*100,2))
print('Precision percent :',round(precision4*100,2))
print('Recall percent :',round(recall4*100,2))
print(confusion_matrix(y_test,y_pred))

y_scoredt = dtmodel.predict_proba(X_test)[:, 1]
precision, recall, thresholds = precision_recall_curve(y_test, y_scoredt)

fig1, ax1 = plt.subplots()
ax1.plot(recall, precision, color='purple')
ax1.set_title('Precision-Recall Curve')
ax1.set_ylabel('Precision')
ax1.set_xlabel('Recall')
plt.show()

y_rocdt = dtmodel.predict_proba(X_test)[::,1]
fpr3, tpr3, _ = metrics.roc_curve(y_test,  y_rocdt)
auc4 = metrics.roc_auc_score(y_test, y_rocdt)
#create ROC curve
#plt.plot(fpr1,tpr1)
plt.figure(figsize=(10, 10))
plt.plot(fpr3,tpr3,label="DTModel_AUC="+str(round(auc4,2)))
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
ax=plt.gca()
ax.locator_params('y', nbins=20)
plt.locator_params('x', nbins=20)
plt.legend(loc=4)
plt.show()

"""**V. SVM Classifier**"""

SVCclassifier = SVC(kernel='poly', max_iter=80)
SVCclassifier.fit(X_train, y_train)

y_pred = SVCclassifier.predict(X_test)
print("SVM CLASSIFIER")
print(classification_report(y_test, y_pred))

accuracy5 = accuracy_score(y_pred,y_test)
f1score5 = f1_score(y_test,y_pred)
recall5 = recall_score(y_test,y_pred)
precision5 = precision_score(y_test,y_pred)
print('SVC accuracy percent : {:.2f}%'.format(accuracy5*100))
print("F1 Score percent : ",round(f1score5*100,2))
print('Precision percent :',round(precision5*100,2))
print('Recall percent :',round(recall5*100,2))
print(confusion_matrix(y_test,y_pred))

y_rocsvm = SVCclassifier.predict(X_test)
fpr4, tpr4, _ = metrics.roc_curve(y_test,  y_rocsvm)
auc5 = metrics.roc_auc_score(y_test, y_rocsvm)
#create ROC curve
#plt.plot(fpr1,tpr1)
plt.figure(figsize=(10, 10))
plt.plot(fpr4,tpr4,label="SVM-Model_AUC="+str(round(auc5,2)))
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
ax=plt.gca()
ax.locator_params('y', nbins=20)
plt.locator_params('x', nbins=20)
plt.legend(loc=4)
plt.show()

"""# Curves"""

y_scoresvm = SVCclassifier.predict(X_test)
precision, recall, thresholds = precision_recall_curve(y_test, y_scoresvm)

fig1, ax1 = plt.subplots()
ax1.plot(recall, precision, color='purple')
ax1.set_title('Precision-Recall Curve')
ax1.set_ylabel('Precision')
ax1.set_xlabel('Recall')
plt.show()

"""# Model Accuracy comparision"""

Models = ['LogisticRegression','RandomForest','KNN','DecisionTree','SVM']
values = [accuracy1,accuracy2,accuracy3,accuracy4,accuracy5]
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(Models, values, color ='maroon',
        width = 0.4)
 
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Models Accuracy")
plt.show()

"""# Precision Comparision"""

Models = ['LogisticRegression','RandomForest','KNN','DecisionTree','SVM']
values = [precision1,precision2,precision3,precision4,precision5]
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(Models, values, color ='black',
        width = 0.4)
 
plt.xlabel("Models")
plt.ylabel("Precision")
plt.title("Models Precision")
plt.show()

"""# Recall comparision"""

Models = ['LogisticRegression','RandomForest','KNN','DecisionTree','SVM']
values = [recall1,recall2,recall3,recall4,recall5]
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(Models, values, color ='red',
        width = 0.4)
 
plt.xlabel("Models")
plt.ylabel("Recall")
plt.title("Models Recall")
plt.show()

"""# F1score comparision"""

Models = ['LogisticRegression','RandomForest','KNN','DecisionTree','SVM']
values = [f1score1,f1score2,f1score3,f1score4,f1score5]
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(Models, values, color ='grey',
        width = 0.4)
 
plt.xlabel("Models")
plt.ylabel("F1-Score")
plt.title("Models F1-Score")
plt.show()

"""# AUC comparision"""

Models = ['LogisticRegression','RandomForest','KNN','DecisionTree','SVM']
values = [auc1,auc2,auc3,auc4,auc5]
  
fig = plt.figure(figsize = (10, 5))
 
# creating the bar plot
plt.bar(Models, values, color ='orange',
        width = 0.4)
 
plt.xlabel("Models")
plt.ylabel("AUC")
plt.title("Models AUC")
plt.show()

"""# ROC Curve comparision"""

plt.figure(0).clf()

plt.plot(fpr,tpr,label="Logistic Regression, AUC="+str(round(auc1,2)))
plt.plot(fpr1,tpr1,label="Random Forest, AUC="+str(round(auc2,2)))
plt.plot(fpr2,tpr2,label="KNN, AUC="+str(round(auc3,2)))
plt.plot(fpr3,tpr3,label="Decision Tree, AUC="+str(round(auc4,2)))
plt.plot(fpr4,tpr4,label="SVM, AUC="+str(round(auc5,2)))
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend()
plt.show()